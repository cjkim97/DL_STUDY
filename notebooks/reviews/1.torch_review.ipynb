{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "Graphics Device with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the Graphics Device GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2+cu110'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "\n",
    "# import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f742402b3d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 기본 리뷰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.FloatTensor([[1,2,3,4,5,6,7,8]])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.view(2,2,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unsqueeze(2).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 의 학습 과정\n",
    "1. 데이터 준비\n",
    "2. 모델 초기화\n",
    "3. optimizer 설정\n",
    "4. 학습\n",
    "    1. 예측 (model.train() 모드 설정)\n",
    "    2. cost 함수 설정\n",
    "    3. 최적화 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Linear Regression\n",
    "### y = w*x + b\n",
    "# 1) 데이터 준비\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "# 2) 모델 초기화 : 각 parameter 를 0으로 초기화\n",
    "W = torch.zeros(1, requires_grad = True) \n",
    "# requires_grad는 autograd 에 모든 연산(operation)들을 추적\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "# 3) 최적화 설정\n",
    "optimizer = optim.SGD([W,b], lr =0.1)\n",
    "\n",
    "# 4) 학습\n",
    "total_epoch = 20 # 총 학습 횟수\n",
    "for epoch in range(total_epoch):\n",
    "    # 예측\n",
    "    hypothesis = x_train*W +b\n",
    "    # cost 함수 설정(MSE)\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    # 최적화 계산\n",
    "    optimizer.zero_grad() \n",
    "    # torch에서 gradient 정보가 남아있기 때문에 초기화를 시켜야 한다\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch : {epoch+1:2d}/{total_epoch} \\\n",
    "          W : {W.item():.4f}, b: {b.item():.4f}, \\\n",
    "          cost : {cost.item() : .6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use nn module\n",
    "# 1) 데이터 준비\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "# 2) 모델설정\n",
    "class SimpleLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1,1) # w의 개수, 결과 값의 개수\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = SimpleLinearRegression()\n",
    "\n",
    "# 3) 최적화 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4) 학습\n",
    "total_epoch = 20\n",
    "for epoch in range(total_epoch):\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.mse_loss(hypothesis, y_train) # 직접 구하지 않고 funtional 사용\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch : {epoch+1:2d}/{total_epoch} \\\n",
    "          W : {W.item():.4f}, b: {b.item():.4f}, \\\n",
    "          cost : {cost.item() : .6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 1) 데이터 준비\n",
    "x_data = torch.FloatTensor(load_iris().data) # 그냥 tensor 를 쓰면 타입 오류가 발생함\n",
    "y_data = torch.tensor(load_iris().target,)\n",
    "\n",
    "# 2) 모델 생성\n",
    "class MultiClassifier(nn.Module):\n",
    "    def __init__(self, w = 4, b = 3): # 컬럼 개수 4개, 결과 값 3개\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(w, b)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultiClassifier()\n",
    "\n",
    "# 3) optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4) 학습\n",
    "epochs = 1000\n",
    "model.train() # 훈련모드 \n",
    "for epoch in range(epochs+1):\n",
    "    \n",
    "    # 1) 예측\n",
    "    hypothesis = model(x_data)\n",
    "    \n",
    "    # 2) cost \n",
    "    cost = F.cross_entropy(hypothesis, y_data) # softmax + nll_loss : cross_entropy, binary class 일 경우 binary_cross_entropy 사용 \n",
    "    \n",
    "    # 3) 최적화 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 로그출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch : {epoch:4d} Cost : {cost.item():.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
