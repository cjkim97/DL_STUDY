{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field # 데이터를 어떻게 처리할지 조절\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "seed = 55\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import de_core_news_sm\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = en_core_web_sm.load()\n",
    "spacy_de = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text): # 역순으로 가져오는게 더 좋은 학습을 했다는 연구가 있음\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "#\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "           init_token = '<sos>',\n",
    "           eos_token = '<eos>',\n",
    "           lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei']\n",
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "# 예시 확인\n",
    "print(train_data.examples[0].src)\n",
    "print(train_data.examples[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_freq = 2 : 2번 이상 등장한 토큰을 출력\n",
    "# 토큰이 1번 등장 시, <unk> 로 대체\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu' # cuda가 왜 안 되지..\n",
    "\n",
    "# print(device) # cuda 확인용 \\\n",
    "batch_size = 128\n",
    "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size = batch_size, device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq 구현"
   ]
  },
  {
   "attachments": {
    "78571a58-9566-4bb5-9730-f481cba5dd78.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:78571a58-9566-4bb5-9730-f481cba5dd78.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, n_layers, dropout): \n",
    "        \n",
    "        # input_size : input 데이터의 vocab_size\n",
    "        # emb_size : 임베딩 사이즈\n",
    "        # hidden_size : 히든 스테이트 차원(=cell state 차원)\n",
    "        # n_layers : RNN 레이어 개수\n",
    "        # dropout : 과적합 방지용\n",
    "        # n_directions =1 // 이때, bidirectional RNN 의 경우는 n_directions = 2 \n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # 임베딩\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        \n",
    "        # encoder 구성을 보통 LSTM, GRU, RNN 층으로 구성하는 편?\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, n_layers, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "         \n",
    "    def forward(self, src):\n",
    "        # x : [src_len, batch_size]\n",
    "\n",
    "        # 임베딩 - 드롭아웃 - lstm \n",
    "        x = self.embedding(src)\n",
    "        x - self.dropout(x)\n",
    "        enc_out, (hidden, cell) = self.lstm(x)\n",
    "        \n",
    "        # enc_out : [src_len, batch_size, hidden_size * n directions]\n",
    "        # hidden, cell : [n_layers * n_directions , batch_size, hidden_size]\n",
    "        \n",
    "        return hidden, cell\n",
    "    \n",
    "# Decoder 구현\n",
    "class Decoder(nn.Module):\n",
    "    # encoder 이후 마지막 hidden_state가 context vector로 들어감\n",
    "    def __init__(self, output_size, emb_size, hidden_size, n_layers, dropout): # input size 와 output size 가 같을 필요가 없음\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size) #fc layer \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, inp, hidden, cell):\n",
    "        # inp : [batch_size]\n",
    "        # hidden, cell : [n_layers * n_directions, batch_size, hidden_size]\n",
    "        inp = inp.unsqueeze(0) # inp -> [1, batch_size]\n",
    "        \n",
    "        x = self.embedding(inp)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        dec_out, (hidden, cell) = self.lstm(x, (hidden,cell)) # 두 인자의 의미..?\n",
    "        # dec_out : [seq_len, batch_size, hidden_size * n_directions]\n",
    "        # hidden, cell : [n_layers * n_directions, batch_size, hidden_size]\n",
    "        \n",
    "        \n",
    "        pred = self.linear(dec_out.squeeze(0))\n",
    "        return pred, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq 구현\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        # src = [src len, batch_Size]\n",
    "        # trg = [trg len, bastch_size]\n",
    "        \n",
    "        trg_len = trg.shape[0] # 타켓 토큰 길이\n",
    "        batch_size - trg.shape[1] \n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # decoder 결과를 저장할 텐서\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        \n",
    "        # encoder 마지막 hidden state : context vector\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # Decoder에 들어갈 첫 input 은 <sos>\n",
    "        inp = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):  # <eos> 제외하고 trg_len-1 만큼 반복\n",
    "            output, hidden, cell = self.decoder(inp,  hidden, cell)\n",
    "            outputs[t] = output \n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio \n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            \n",
    "            # 일정 확률로 다음 LSTM 블록에 이전 예측 결과 값이 아니라 target(정답)을 입력\n",
    "            inp = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7853"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SRC.vocab.itos) # itos : integer to string? 반대로 stoi : string to integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 하이퍼파라미터\n",
    "- input_size : input 데이터의 vocab_size\n",
    "- emb_size : 임베딩 사이즈\n",
    "- hidden_size : 히든 스테이트 차원(=cell state 차원)\n",
    "- n_layers : RNN 레이어 개수\n",
    "- dropout : 과적합 방지용\n",
    "- n_directions =1 // 이때, bidirectional RNN 의 경우는 n_directions = 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "inp_dim = len(SRC.vocab)\n",
    "out_dim = len(TRG.vocab)\n",
    "\n",
    "enc_emb_dim = 256 #임베딩 차원\n",
    "dec_emb_dim = 256\n",
    "\n",
    "hid_dim = 512 # hidden state 차원\n",
    "n_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "enc = Encoder(input_size=inp_dim, emb_size=enc_emb_dim, hidden_size= hid_dim, n_layers=n_layers, dropout=enc_dropout)\n",
    "dec = Decoder(output_size=out_dim, emb_size=dec_emb_dim, hidden_size= hid_dim, n_layers=n_layers, dropout=dec_dropout)\n",
    "model = Seq2Seq(enc,dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (linear): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 초기화\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,898,501 trainableparameters\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 가능한 파라미터 수 측정\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainableparameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# loss function\n",
    "trg_pad_idx = TRG.vocab.stoi[TRG.pad_token] # string to integer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx) # pad 에 해당하는 index는 무시하도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    print('train mode')\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i , batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg) # [trg len, batch size, output dim]\n",
    "        output_size = output.shape[-1]\n",
    "        \n",
    "        #print(f'output shape : {output.shape}')\n",
    "        output = output[1:].view(-1, output_size)\n",
    "        #print(f'output shape : {output.shape}')\n",
    "        #print(f'trg shape : {trg.shape}')\n",
    "        trg = trg[1:].view(-1)\n",
    "        #print(f'trg shape : {trg.shape}')\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 기울기 clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    print('eval mode')\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            # [trg_len, batch_size, output_size]\n",
    "            output = model(src, trg, teacher_forcing_ratio = 0) # teacher forcing을 없애주기 위함\n",
    "            output_size = output.shape[-1]\n",
    "            #rint(f'output shape : {output.shape}')\n",
    "            output = output[1:].view(-1, output_size) # [(trg_len-1)*batch_size, output_size]\n",
    "            #rint(f'output shape : {output.shape}')\n",
    "            \n",
    "            #rint(f'trg shape : {trg.shape}')\n",
    "            trg = trg[1:].view(-1)\n",
    "            #print(f'trg shape : {trg.shape}')\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 1\n",
    "clip = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "#     end_time = time.time()\n",
    "    \n",
    "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
